Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: C:\Users\twank\anaconda3\envs\DewiAML\lib\site-packages\lpips\weights\v0.1\alex.pth
Namespace(batch_size=8, conv_on_input=0, dataset_name='mnist', decouple_beta=0.1, device='cuda', display_interval=100, filter_size=5, gen_frm_dir='results_finetuning/blocks_1010', img_channel=1, img_width=64, injection_action='concat', input_length=10, is_training=1, layer_norm=0, lr=0.0001, max_iterations=8000, model_name='predrnn_v2', n_gpu=1, noise='blocks', noise_ratio=0.1, noise_size=10, num_action_ch=4, num_hidden='128,128,128,128', num_save_samples=10, parameters=['conv_last.weight'], patch_size=4, pretrained_model='./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks5', r_exp_alpha=2500, r_sampling_step_1=25000.0, r_sampling_step_2=50000, res_on_conv=0, reverse_input=1, reverse_scheduled_sampling=1, sampling_changing_rate=2e-05, sampling_start_value=1.0, sampling_stop_iter=50000, save_dir='checkpoints_finetuning/mnist_predrnn_v2', scheduled_sampling=1, snapshot_interval=10000, stride=1, test_interval=10000, total_length=20, train_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-train.npz', valid_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-test.npz', visual=0, visual_path='./decoupling_visual')
clips
(2, 3000, 2)
dims
(1, 3)
input_raw_data
(60000, 1, 64, 64)
clips
(2, 10000, 2)
dims
(1, 3)
input_raw_data
(200000, 1, 64, 64)
load model: ./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks5
Updating 1 parameter(s): ['conv_last.weight']
2025-07-06 01:35:21 itr: 100
training loss: 0.028775852173566818
2025-07-06 01:37:25 itr: 200
training loss: 0.02673180028796196
2025-07-06 01:39:29 itr: 300
training loss: 0.027345210313796997
2025-07-06 01:41:33 itr: 400
training loss: 0.028585726395249367
2025-07-06 01:43:37 itr: 500
training loss: 0.027954116463661194
2025-07-06 01:45:41 itr: 600
training loss: 0.026325775310397148
2025-07-06 01:47:45 itr: 700
training loss: 0.030452946200966835
2025-07-06 01:49:49 itr: 800
training loss: 0.02544022910296917
2025-07-06 01:51:54 itr: 900
training loss: 0.026615489274263382
2025-07-06 01:53:58 itr: 1000
training loss: 0.027271514758467674
2025-07-06 01:56:02 itr: 1100
training loss: 0.02812020108103752
2025-07-06 01:58:06 itr: 1200
training loss: 0.02794259414076805
2025-07-06 02:00:10 itr: 1300
training loss: 0.028463875874876976
2025-07-06 02:02:14 itr: 1400
training loss: 0.026552483439445496
2025-07-06 02:04:18 itr: 1500
training loss: 0.02552228607237339
2025-07-06 02:06:22 itr: 1600
training loss: 0.02749277651309967
2025-07-06 02:08:26 itr: 1700
training loss: 0.026975464075803757
2025-07-06 02:10:30 itr: 1800
training loss: 0.028316335752606392
2025-07-06 02:12:34 itr: 1900
training loss: 0.028613638132810593
2025-07-06 02:14:38 itr: 2000
training loss: 0.0269259512424469
2025-07-06 02:16:42 itr: 2100
training loss: 0.029714804142713547
2025-07-06 02:18:46 itr: 2200
training loss: 0.0280834399163723
2025-07-06 02:20:51 itr: 2300
training loss: 0.02629246562719345
2025-07-06 02:22:55 itr: 2400
training loss: 0.026386069133877754
2025-07-06 02:24:59 itr: 2500
training loss: 0.027381811290979385
2025-07-06 02:27:03 itr: 2600
training loss: 0.027415858581662178
2025-07-06 02:29:07 itr: 2700
training loss: 0.028962433338165283
2025-07-06 02:31:11 itr: 2800
training loss: 0.029245425015687943
2025-07-06 02:33:15 itr: 2900
training loss: 0.030015546828508377
2025-07-06 02:35:19 itr: 3000
training loss: 0.027950473129749298
2025-07-06 02:37:23 itr: 3100
training loss: 0.02911118045449257
2025-07-06 02:39:27 itr: 3200
training loss: 0.028446979820728302
2025-07-06 02:41:31 itr: 3300
training loss: 0.02968176081776619
2025-07-06 02:43:35 itr: 3400
training loss: 0.03232976421713829
2025-07-06 02:45:39 itr: 3500
training loss: 0.025363434106111526
2025-07-06 02:47:43 itr: 3600
training loss: 0.027180202305316925
2025-07-06 02:49:47 itr: 3700
training loss: 0.02742863819003105
2025-07-06 02:51:52 itr: 3800
training loss: 0.028497982770204544
2025-07-06 02:53:55 itr: 3900
training loss: 0.027027463540434837
2025-07-06 02:55:59 itr: 4000
training loss: 0.028056027367711067
2025-07-06 02:58:03 itr: 4100
training loss: 0.029166204854846
2025-07-06 03:00:07 itr: 4200
training loss: 0.029409676790237427
2025-07-06 03:02:11 itr: 4300
training loss: 0.0295882448554039
2025-07-06 03:04:15 itr: 4400
training loss: 0.027411382645368576
2025-07-06 03:06:19 itr: 4500
training loss: 0.027420390397310257
2025-07-06 03:08:24 itr: 4600
training loss: 0.026285747066140175
2025-07-06 03:10:28 itr: 4700
training loss: 0.02933388575911522
2025-07-06 03:12:32 itr: 4800
training loss: 0.027009831741452217
2025-07-06 03:14:36 itr: 4900
training loss: 0.02816440537571907
2025-07-06 03:16:40 itr: 5000
training loss: 0.02848180942237377
2025-07-06 03:18:44 itr: 5100
training loss: 0.027744587510824203
2025-07-06 03:20:48 itr: 5200
training loss: 0.026207000017166138
2025-07-06 03:22:52 itr: 5300
training loss: 0.03006378933787346
2025-07-06 03:24:56 itr: 5400
training loss: 0.02617177739739418
2025-07-06 03:27:00 itr: 5500
training loss: 0.026714853942394257
2025-07-06 03:29:04 itr: 5600
training loss: 0.02507052570581436
2025-07-06 03:31:08 itr: 5700
training loss: 0.0273900143802166
2025-07-06 03:33:12 itr: 5800
training loss: 0.02677302435040474
2025-07-06 03:35:16 itr: 5900
training loss: 0.0277332104742527
2025-07-06 03:37:20 itr: 6000
training loss: 0.025048257783055305
2025-07-06 03:39:24 itr: 6100
training loss: 0.02543020062148571
2025-07-06 03:41:28 itr: 6200
training loss: 0.026345983147621155
2025-07-06 03:43:32 itr: 6300
training loss: 0.027745716273784637
2025-07-06 03:45:36 itr: 6400
training loss: 0.02941102348268032
2025-07-06 03:47:40 itr: 6500
training loss: 0.028977496549487114
2025-07-06 03:49:44 itr: 6600
training loss: 0.02757403813302517
2025-07-06 03:51:48 itr: 6700
training loss: 0.028785020112991333
2025-07-06 03:53:52 itr: 6800
training loss: 0.02563883550465107
2025-07-06 03:55:57 itr: 6900
training loss: 0.028285911306738853
2025-07-06 03:58:01 itr: 7000
training loss: 0.028692927211523056
2025-07-06 04:00:05 itr: 7100
training loss: 0.02902200259268284
2025-07-06 04:02:09 itr: 7200
training loss: 0.027216654270887375
2025-07-06 04:04:13 itr: 7300
training loss: 0.027405809611082077
2025-07-06 04:06:17 itr: 7400
training loss: 0.03257223963737488
2025-07-06 04:08:21 itr: 7500
training loss: 0.02622218243777752
2025-07-06 04:10:25 itr: 7600
training loss: 0.03000655025243759
2025-07-06 04:12:29 itr: 7700
training loss: 0.02661973237991333
2025-07-06 04:14:33 itr: 7800
training loss: 0.028480108827352524
2025-07-06 04:16:37 itr: 7900
training loss: 0.02663453482091427
2025-07-06 04:18:41 itr: 8000
training loss: 0.02823774516582489
clips
(2, 3000, 2)
dims
(1, 3)
input_raw_data
(60000, 1, 64, 64)
2025-07-06 04:18:43 test...
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: C:\Users\twank\anaconda3\envs\DewiAML\lib\site-packages\lpips\weights\v0.1\alex.pth
Namespace(batch_size=8, conv_on_input=0, dataset_name='mnist', decouple_beta=0.1, device='cuda', display_interval=100, filter_size=5, gen_frm_dir='results_finetuning/test_end', img_channel=1, img_width=64, injection_action='concat', input_length=10, is_training=0, layer_norm=0, lr=0.0001, max_iterations=80000, model_name='predrnn_v2', n_gpu=1, noise=None, noise_ratio=0.1, noise_size=10, num_action_ch=4, num_hidden='128,128,128,128', num_save_samples=10, patch_size=4, pretrained_model='./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10', r_exp_alpha=2500, r_sampling_step_1=25000.0, r_sampling_step_2=50000, res_on_conv=0, reverse_input=1, reverse_scheduled_sampling=1, sampling_changing_rate=2e-05, sampling_start_value=1.0, sampling_stop_iter=50000, save_dir='checkpoints/mnist_predrnn_v2', scheduled_sampling=1, snapshot_interval=5000, stride=1, test_interval=5000, total_length=20, train_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-train.npz', valid_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-test.npz', visual=0, visual_path='./decoupling_visual')
Initializing models
load model: ./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: C:\Users\twank\anaconda3\envs\DewiAML\lib\site-packages\lpips\weights\v0.1\alex.pth
Namespace(batch_size=8, conv_on_input=0, dataset_name='mnist', decouple_beta=0.1, device='cuda', display_interval=100, filter_size=5, gen_frm_dir='results_finetuning/random_end', img_channel=1, img_width=64, injection_action='concat', input_length=10, is_training=0, layer_norm=0, lr=0.0001, max_iterations=80000, model_name='predrnn_v2', n_gpu=1, noise='random', noise_ratio=0.1, noise_size=10, num_action_ch=4, num_hidden='128,128,128,128', num_save_samples=10, patch_size=4, pretrained_model='./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10', r_exp_alpha=2500, r_sampling_step_1=25000.0, r_sampling_step_2=50000, res_on_conv=0, reverse_input=1, reverse_scheduled_sampling=1, sampling_changing_rate=2e-05, sampling_start_value=1.0, sampling_stop_iter=50000, save_dir='checkpoints/mnist_predrnn_v2', scheduled_sampling=1, snapshot_interval=5000, stride=1, test_interval=5000, total_length=20, train_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-train.npz', valid_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-test.npz', visual=0, visual_path='./decoupling_visual')
Initializing models
load model: ./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: C:\Users\twank\anaconda3\envs\DewiAML\lib\site-packages\lpips\weights\v0.1\alex.pth
Namespace(batch_size=8, conv_on_input=0, dataset_name='mnist', decouple_beta=0.1, device='cuda', display_interval=100, filter_size=5, gen_frm_dir='results_finetuning/rows_end', img_channel=1, img_width=64, injection_action='concat', input_length=10, is_training=0, layer_norm=0, lr=0.0001, max_iterations=80000, model_name='predrnn_v2', n_gpu=1, noise='rows', noise_ratio=0.1, noise_size=10, num_action_ch=4, num_hidden='128,128,128,128', num_save_samples=10, patch_size=4, pretrained_model='./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10', r_exp_alpha=2500, r_sampling_step_1=25000.0, r_sampling_step_2=50000, res_on_conv=0, reverse_input=1, reverse_scheduled_sampling=1, sampling_changing_rate=2e-05, sampling_start_value=1.0, sampling_stop_iter=50000, save_dir='checkpoints/mnist_predrnn_v2', scheduled_sampling=1, snapshot_interval=5000, stride=1, test_interval=5000, total_length=20, train_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-train.npz', valid_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-test.npz', visual=0, visual_path='./decoupling_visual')
Initializing models
load model: ./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: C:\Users\twank\anaconda3\envs\DewiAML\lib\site-packages\lpips\weights\v0.1\alex.pth
Namespace(batch_size=8, conv_on_input=0, dataset_name='mnist', decouple_beta=0.1, device='cuda', display_interval=100, filter_size=5, gen_frm_dir='results_finetuning/blocks_22_end', img_channel=1, img_width=64, injection_action='concat', input_length=10, is_training=0, layer_norm=0, lr=0.0001, max_iterations=80000, model_name='predrnn_v2', n_gpu=1, noise='blocks', noise_ratio=0.1, noise_size=2, num_action_ch=4, num_hidden='128,128,128,128', num_save_samples=10, patch_size=4, pretrained_model='./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10', r_exp_alpha=2500, r_sampling_step_1=25000.0, r_sampling_step_2=50000, res_on_conv=0, reverse_input=1, reverse_scheduled_sampling=1, sampling_changing_rate=2e-05, sampling_start_value=1.0, sampling_stop_iter=50000, save_dir='checkpoints/mnist_predrnn_v2', scheduled_sampling=1, snapshot_interval=5000, stride=1, test_interval=5000, total_length=20, train_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-train.npz', valid_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-test.npz', visual=0, visual_path='./decoupling_visual')
Initializing models
load model: ./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: C:\Users\twank\anaconda3\envs\DewiAML\lib\site-packages\lpips\weights\v0.1\alex.pth
Namespace(batch_size=8, conv_on_input=0, dataset_name='mnist', decouple_beta=0.1, device='cuda', display_interval=100, filter_size=5, gen_frm_dir='results_finetuning/blocks_55_end', img_channel=1, img_width=64, injection_action='concat', input_length=10, is_training=0, layer_norm=0, lr=0.0001, max_iterations=80000, model_name='predrnn_v2', n_gpu=1, noise='blocks', noise_ratio=0.1, noise_size=5, num_action_ch=4, num_hidden='128,128,128,128', num_save_samples=10, patch_size=4, pretrained_model='./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10', r_exp_alpha=2500, r_sampling_step_1=25000.0, r_sampling_step_2=50000, res_on_conv=0, reverse_input=1, reverse_scheduled_sampling=1, sampling_changing_rate=2e-05, sampling_start_value=1.0, sampling_stop_iter=50000, save_dir='checkpoints/mnist_predrnn_v2', scheduled_sampling=1, snapshot_interval=5000, stride=1, test_interval=5000, total_length=20, train_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-train.npz', valid_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-test.npz', visual=0, visual_path='./decoupling_visual')
Initializing models
load model: ./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: C:\Users\twank\anaconda3\envs\DewiAML\lib\site-packages\lpips\weights\v0.1\alex.pth
Namespace(batch_size=8, conv_on_input=0, dataset_name='mnist', decouple_beta=0.1, device='cuda', display_interval=100, filter_size=5, gen_frm_dir='results_finetuning/blocks_1010_end', img_channel=1, img_width=64, injection_action='concat', input_length=10, is_training=0, layer_norm=0, lr=0.0001, max_iterations=80000, model_name='predrnn_v2', n_gpu=1, noise='blocks', noise_ratio=0.1, noise_size=10, num_action_ch=4, num_hidden='128,128,128,128', num_save_samples=10, patch_size=4, pretrained_model='./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10', r_exp_alpha=2500, r_sampling_step_1=25000.0, r_sampling_step_2=50000, res_on_conv=0, reverse_input=1, reverse_scheduled_sampling=1, sampling_changing_rate=2e-05, sampling_start_value=1.0, sampling_stop_iter=50000, save_dir='checkpoints/mnist_predrnn_v2', scheduled_sampling=1, snapshot_interval=5000, stride=1, test_interval=5000, total_length=20, train_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-train.npz', valid_data_paths='C:/Users/twank/Documents/Dewi/predrnn-pytorch-master/predrnn-pytorch-master/moving-mnist-example/moving-mnist-test.npz', visual=0, visual_path='./decoupling_visual')
Initializing models
load model: ./checkpoints_finetuning/mnist_predrnn_v2/model.ckpt-8000-blocks10